{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed3bcec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('722_I4').getOrCreate()\n",
    "from pyspark.sql.functions import mean,when\n",
    "from pyspark.sql.functions import count, col, desc\n",
    "from pyspark.sql.functions import sum as spark_sum\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50420d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.read.csv('Diabetes_1.csv', inferSchema=True, header=True)\n",
    "df1.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3d88dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- smoking_history: string (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- HbA1c_level: double (nullable = true)\n",
      " |-- blood_glucose_level: integer (nullable = true)\n",
      " |-- diabetes: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 106935:>                                                     (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df2 = spark.read.csv('Diabetes_2.csv', inferSchema=True, header=True)\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04d8f8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- smoking_history: string (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- diabetes: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df2.drop('blood_glucose_level', 'HbA1c_level')\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f41eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+\n",
      "| ID|gender|age|\n",
      "+---+------+---+\n",
      "|  0|   164|157|\n",
      "+---+------+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-------------+---------------+---+--------+\n",
      "| ID|hypertension|heart_disease|smoking_history|bmi|diabetes|\n",
      "+---+------------+-------------+---------------+---+--------+\n",
      "|  0|         161|           95|            253|160|     184|\n",
      "+---+------------+-------------+---------------+---+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 107011:(0 + 0) / 2][Stage 107012:(0 + 2) / 2][Stage 107013:(0 + 0) / 1]1]\r"
     ]
    }
   ],
   "source": [
    "missing_counts = df1.select([spark_sum(col(c).isNull().cast(\"int\")).alias(c) for c in df1.columns])\n",
    "missing_counts.show()\n",
    "missing_counts = df2.select([spark_sum(col(c).isNull().cast(\"int\")).alias(c) for c in df2.columns])\n",
    "missing_counts.show()\n",
    "avg_val = df1.agg(mean(df1['age'])).first()[0]\n",
    "df1 = df1.fillna({'age': avg_val})\n",
    "mode_val = df1.groupBy('gender').agg(count('gender').alias('count')).orderBy(desc('count')).first()[0]\n",
    "df1 = df1.fillna({'gender': mode_val})\n",
    "\n",
    "avg_val = df2.agg(mean(df2['hypertension'])).first()[0]\n",
    "df2 = df2.fillna({'hypertension': avg_val})\n",
    "avg_val = df2.agg(mean(df2['heart_disease'])).first()[0]\n",
    "df2 = df2.fillna({'heart_disease': avg_val})\n",
    "avg_val = df2.agg(mean(df2['bmi'])).first()[0]\n",
    "df2 = df2.fillna({'bmi': avg_val})\n",
    "avg_val = df2.agg(mean(df2['diabetes'])).first()[0]\n",
    "df2 = df2.fillna({'diabetes': avg_val})\n",
    "mode_val = df2.groupBy('smoking_history').agg(count('smoking_history').alias('count')).orderBy(desc('count')).first()[0]\n",
    "df2 = df2.fillna({'smoking_history': mode_val})\n",
    "\n",
    "print(\"Number of entries: \", df1.count())\n",
    "print(\"Number of entries: \", df2.count())\n",
    "missing_counts = df1.select([spark_sum(col(c).isNull().cast(\"int\")).alias(c) for c in df1.columns])\n",
    "missing_counts.show()\n",
    "missing_counts = df2.select([spark_sum(col(c).isNull().cast(\"int\")).alias(c) for c in df2.columns])\n",
    "missing_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ead33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2 = df2.filter((df2.bmi <= 100) & (df2.bmi >= 0))\n",
    "df_pd = df2.toPandas()\n",
    "plt.scatter(range(len(df_pd['bmi'])), df_pd['bmi'])\n",
    "plt.title('Scatter plot for BMI')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f66165",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.join(df2, 'id', 'inner')\n",
    "df.printSchema()\n",
    "print(\"Number of entries: \", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334e88b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_bins = [0, 2, 4, 13, 20, 30, 50, 65, 81]\n",
    "age_labels = [\"Infants\", \"Toddlers\", \"Children\", \"Teenagers\", \"Young\", \"Middle-aged\", \"Older adults\", \"Seniors\"]\n",
    "\n",
    "age_column_expr = when(col(\"age\") < age_bins[0], None)  \n",
    "for i in range(len(age_bins) - 1):\n",
    "    age_column_expr = age_column_expr.when((col(\"age\") >= age_bins[i]) & (col(\"age\") < age_bins[i + 1]), age_labels[i])\n",
    "\n",
    "df = df.withColumn(\"Age group\", age_column_expr)\n",
    "\n",
    "bmi_bins = [0, 18.50, 24.99, 29.99, 34.99, 39.99, 100]\n",
    "bmi_labels = [\"Underweight\", \"Normal weight\", \"Overweight\", \"Obesity I\", \"Obesity II\", \"Obesity III\"]\n",
    "\n",
    "bmi_column_expr = when(col(\"bmi\") < bmi_bins[0], None)  \n",
    "for i in range(len(bmi_bins) - 1):\n",
    "    bmi_column_expr = bmi_column_expr.when((col(\"bmi\") >= bmi_bins[i]) & (col(\"bmi\") < bmi_bins[i + 1]), bmi_labels[i])\n",
    "\n",
    "df = df.withColumn(\"Bmi class\", bmi_column_expr)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158580ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_features = ['hypertension', 'heart_disease']\n",
    "\n",
    "df = df.withColumn(\"Medical_History_Count\", sum(col(feature) for feature in medical_features))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0729d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"Age group\", outputCol=\"Age group_index\")\n",
    "indexed_model = indexer.fit(df)\n",
    "df = indexed_model.transform(df)\n",
    "labels = indexed_model.labels\n",
    "encoder = OneHotEncoder(inputCols=[\"Age group_index\"], outputCols=[\"Age group_encoded\"], dropLast=False)\n",
    "df = encoder.fit(df).transform(df)\n",
    "num_categories_age = df.select(\"Age group_index\").distinct().count()\n",
    "df = df.withColumn(\"Age group_array\", vector_to_array(\"Age group_encoded\"))\n",
    "for i, label in enumerate(labels):\n",
    "    df = df.withColumn(f\"Age group_{label}\", col(\"Age group_array\")[i].cast(\"int\"))\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"Bmi class\", outputCol=\"Bmi class_index\")\n",
    "indexed_model = indexer.fit(df)\n",
    "df = indexed_model.transform(df)\n",
    "labels = indexed_model.labels\n",
    "encoder = OneHotEncoder(inputCols=[\"Bmi class_index\"], outputCols=[\"Bmi class_encoded\"], dropLast=False)\n",
    "df = encoder.fit(df).transform(df)\n",
    "num_categories_bmi = df.select(\"Bmi class_index\").distinct().count()\n",
    "df = df.withColumn(\"Bmi class_array\", vector_to_array(\"Bmi class_encoded\"))\n",
    "for i, label in enumerate(labels):\n",
    "    df = df.withColumn(f\"Bmi class_{label}\", col(\"Bmi class_array\")[i].cast(\"int\"))\n",
    "\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"gender\", outputCol=\"gender_index\")\n",
    "indexed_model = indexer.fit(df)\n",
    "df = indexed_model.transform(df)\n",
    "labels = indexed_model.labels\n",
    "encoder = OneHotEncoder(inputCols=[\"gender_index\"], outputCols=[\"gender_encoded\"], dropLast=False)\n",
    "df = encoder.fit(df).transform(df)\n",
    "num_categories_gender = df.select(\"gender_index\").distinct().count()\n",
    "df = df.withColumn(\"gender_array\", vector_to_array(\"gender_encoded\"))\n",
    "for i, label in enumerate(labels):\n",
    "    df = df.withColumn(f\"gender_{label}\", col(\"gender_array\")[i].cast(\"int\"))\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"smoking_history\", outputCol=\"smoking_history_index\")\n",
    "indexed_model = indexer.fit(df)\n",
    "df = indexed_model.transform(df)\n",
    "labels = indexed_model.labels\n",
    "encoder = OneHotEncoder(inputCols=[\"smoking_history_index\"], outputCols=[\"smoking_history_encoded\"], dropLast=False)\n",
    "df = encoder.fit(df).transform(df)\n",
    "num_categories_smoking = df.select(\"smoking_history_index\").distinct().count()\n",
    "df = df.withColumn(\"smoking_history_array\", vector_to_array(\"smoking_history_encoded\"))\n",
    "for i, label in enumerate(labels):\n",
    "    df = df.withColumn(f\"smoking_history_{label}\", col(\"smoking_history_array\")[i].cast(\"int\"))\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"Medical_History_Count\", outputCol=\"Medical_History_Count_index\")\n",
    "indexed_model = indexer.fit(df)\n",
    "df = indexed_model.transform(df)\n",
    "labels = indexed_model.labels\n",
    "encoder = OneHotEncoder(inputCols=[\"Medical_History_Count_index\"], outputCols=[\"Medical_History_Count_encoded\"], dropLast=False)\n",
    "df = encoder.fit(df).transform(df)\n",
    "num_categories_medical = df.select(\"Medical_History_Count_index\").distinct().count()\n",
    "df = df.withColumn(\"Medical_History_Count_array\", vector_to_array(\"Medical_History_Count_encoded\"))\n",
    "for i, label in enumerate(labels):\n",
    "    df = df.withColumn(f\"Medical_History_Count_{label}\", col(\"Medical_History_Count_array\")[i].cast(\"int\"))\n",
    "\n",
    "columns_to_drop = [\"Age group_index\", \"Bmi class_index\", \"gender_index\", \"smoking_history_index\", \n",
    "                   \"Medical_History_Count_index\", \"Age group_encoded\", \"Bmi class_encoded\", \n",
    "                   \"gender_encoded\", \"smoking_history_encoded\", \"Medical_History_Count_encoded\", \n",
    "                   \"Age group_array\", \"Bmi class_array\", \"gender_array\", \"smoking_history_array\", \n",
    "                   \"Medical_History_Count_array\"]\n",
    "df = df.drop(*columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5683683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_to_keep = ['hypertension','heart_disease','diabetes','Age group_Middle-aged','Age group_Older adults',\n",
    "                   'Age group_Seniors','Age group_Young','Age group_Children','Age group_Teenagers','Age group_Toddlers',\n",
    "                   'Age group_Infants','Bmi class_Overweight','Bmi class_Normal weight','Bmi class_Obesity I',\n",
    "                   'Bmi class_Underweight','Bmi class_Obesity II','Bmi class_Obesity III', 'gender_Female','gender_Male',\n",
    "                   'gender_Other', 'smoking_history_never','smoking_history_former','smoking_history_current','smoking_history_not current',\n",
    "                   'smoking_history_ever','Medical_History_Count_0','Medical_History_Count_1','Medical_History_Count_2'\n",
    "]\n",
    "\n",
    "df = df.select(columns_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dd7b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df2[df2['smoking_history'] != 'No Info']\n",
    "print(\"Number of entries: \", df_select.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8148ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "input_columns = [col for col in df.columns if col != 'diabetes']\n",
    "assembler = VectorAssembler(inputCols=input_columns, outputCol=\"features\")\n",
    "data = assembler.transform(df)\n",
    "\n",
    "x = data.select(\"features\")\n",
    "y = data.select(\"diabetes\")\n",
    "\n",
    "clf = RandomForestClassifier(numTrees=100, labelCol=\"diabetes\", featuresCol=\"features\")\n",
    "model = clf.fit(data)\n",
    "\n",
    "importances = model.featureImportances\n",
    "feature_importance = dict(zip(input_columns, importances))\n",
    "\n",
    "sorted_feature_importance = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "for feature, importance in sorted_feature_importance:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771f2c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_important_features = ['Age group_Toddlers', 'Age group_Infants', 'gender_Other']\n",
    "for feature in non_important_features:\n",
    "    df = df.drop(feature)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9152e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_counts = df.groupBy('diabetes').count().collect()\n",
    "print({row['diabetes']: row['count'] for row in diabetes_counts})\n",
    "\n",
    "df_high = df.filter(col('diabetes') == 0)\n",
    "df_low = df.filter(col('diabetes') == 1)\n",
    "fraction = df_low.count() / df_high.count()\n",
    "df_high_reduce = df_high.sample(False, fraction)\n",
    "df_reduced = df_low.union(df_high_reduce)\n",
    "\n",
    "reduced_diabetes_counts = df_reduced.groupBy('diabetes').count().collect()\n",
    "print({row['diabetes']: row['count'] for row in reduced_diabetes_counts})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f9ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "df_reduced = df_reduced.withColumn(\"diabetes\", col(\"diabetes\").cast(\"double\"))\n",
    "feature_cols = list(df_reduced.columns)\n",
    "feature_cols.remove(\"diabetes\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "train_data, test_data = df_reduced.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier(labelCol=\"diabetes\", featuresCol=\"features\")\n",
    "pipeline = Pipeline(stages=[assembler, dt_classifier])\n",
    "dt_model = pipeline.fit(train_data)\n",
    "predictions_dt = dt_model.transform(test_data)\n",
    "\n",
    "accuracy_dt = MulticlassClassificationEvaluator(labelCol=\"diabetes\", predictionCol=\"prediction\", metricName=\"accuracy\").evaluate(predictions_dt)\n",
    "\n",
    "predictionLabels_dt = predictions_dt.select(\"prediction\", \"diabetes\").rdd\n",
    "metrics_dt = MulticlassMetrics(predictionLabels_dt)\n",
    "\n",
    "precision_0_dt = metrics_dt.precision(label=0.0)\n",
    "recall_0_dt = metrics_dt.recall(label=0.0)\n",
    "f1Score_0_dt = metrics_dt.fMeasure(label=0.0)\n",
    "precision_1_dt = metrics_dt.precision(label=1.0)\n",
    "recall_1_dt = metrics_dt.recall(label=1.0)\n",
    "f1Score_1_dt = metrics_dt.fMeasure(label=1.0)\n",
    "\n",
    "print(f\"Decision Tree - Accuracy: {accuracy_dt:.4f}\")\n",
    "print(f\"Decision Tree - 0 - Precision: {precision_0_dt:.4f}\")\n",
    "print(f\"Decision Tree - 0 - Recall: {recall_0_dt:.4f}\")\n",
    "print(f\"Decision Tree - 0 - F1 Score: {f1Score_0_dt:.4f}\")\n",
    "print(f\"Decision Tree - 1 - Precision: {precision_1_dt:.4f}\")\n",
    "print(f\"Decision Tree - 1 - Recall: {recall_1_dt:.4f}\")\n",
    "print(f\"Decision Tree - 1 - F1 Score: {f1Score_1_dt:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6812f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "train_data, test_data = df_reduced.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(labelCol=\"diabetes\", featuresCol=\"features\")\n",
    "pipeline = Pipeline(stages=[assembler, rf_classifier])\n",
    "rf_model = pipeline.fit(train_data)\n",
    "\n",
    "predictions_rf = rf_model.transform(test_data)\n",
    "\n",
    "accuracy_rf = MulticlassClassificationEvaluator(labelCol=\"diabetes\", predictionCol=\"prediction\", metricName=\"accuracy\").evaluate(predictions_rf)\n",
    "\n",
    "predictionLabels_rf = predictions_rf.select(\"prediction\", \"diabetes\").rdd\n",
    "metrics_rf = MulticlassMetrics(predictionLabels_rf)\n",
    "\n",
    "precision_0_rf = metrics_rf.precision(label=0.0)\n",
    "recall_0_rf = metrics_rf.recall(label=0.0)\n",
    "f1Score_0_rf = metrics_rf.fMeasure(label=0.0)\n",
    "precision_1_rf = metrics_rf.precision(label=1.0)\n",
    "recall_1_rf = metrics_rf.recall(label=1.0)\n",
    "f1Score_1_rf = metrics_rf.fMeasure(label=1.0)\n",
    "\n",
    "print(f\"Random Forest - Accuracy: {accuracy_rf:.4f}\")\n",
    "print(f\"Random Forest - 0 - Precision: {precision_0_rf:.4f}\")\n",
    "print(f\"Random Forest - 0 - Recall: {recall_0_rf:.4f}\")\n",
    "print(f\"Random Forest - 0 - F1 Score: {f1Score_0_rf:.4f}\")\n",
    "print(f\"Random Forest - 1 - Precision: {precision_1_rf:.4f}\")\n",
    "print(f\"Random Forest - 1 - Recall: {recall_1_rf:.4f}\")\n",
    "print(f\"Random Forest - 1 - F1 Score: {f1Score_1_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc6eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "train_data, test_data = df_reduced.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "gbt_classifier = GBTClassifier(labelCol=\"diabetes\", featuresCol=\"features\")\n",
    "pipeline = Pipeline(stages=[assembler, gbt_classifier])\n",
    "gbt_model = pipeline.fit(train_data)\n",
    "\n",
    "predictions_gbt = gbt_model.transform(test_data)\n",
    "\n",
    "accuracy_gbt = MulticlassClassificationEvaluator(labelCol=\"diabetes\", predictionCol=\"prediction\", metricName=\"accuracy\").evaluate(predictions_gbt)\n",
    "\n",
    "predictionLabels_gbt = predictions_gbt.select(\"prediction\", \"diabetes\").rdd\n",
    "metrics_gbt = MulticlassMetrics(predictionLabels_gbt)\n",
    "\n",
    "precision_0_gbt = metrics_gbt.precision(label=0.0)\n",
    "recall_0_gbt = metrics_gbt.recall(label=0.0)\n",
    "f1Score_0_gbt = metrics_gbt.fMeasure(label=0.0)\n",
    "precision_1_gbt = metrics_gbt.precision(label=1.0)\n",
    "recall_1_gbt = metrics_gbt.recall(label=1.0)\n",
    "f1Score_1_gbt = metrics_gbt.fMeasure(label=1.0)\n",
    "\n",
    "print(f\"Gradient Boosted Trees - Accuracy: {accuracy_gbt:.4f}\")\n",
    "print(f\"Gradient Boosted Trees - 0 - Precision: {precision_0_gbt:.4f}\")\n",
    "print(f\"Gradient Boosted Trees - 0 - Recall: {recall_0_gbt:.4f}\")\n",
    "print(f\"Gradient Boosted Trees - 0 - F1 Score: {f1Score_0_gbt:.4f}\")\n",
    "print(f\"Gradient Boosted Trees - 1 - Precision: {precision_1_gbt:.4f}\")\n",
    "print(f\"Gradient Boosted Trees - 1 - Recall: {recall_1_gbt:.4f}\")\n",
    "print(f\"Gradient Boosted Trees - 1 - F1 Score: {f1Score_1_gbt:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eb5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "train_data, test_data = df_reduced.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "gbt_classifier = GBTClassifier(labelCol=\"diabetes\", featuresCol=\"features\")\n",
    "pipeline = Pipeline(stages=[assembler, gbt_classifier])\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(gbt_classifier.maxDepth, [2, 4, 6])\n",
    "             .addGrid(gbt_classifier.maxIter, [10, 20])\n",
    "             .addGrid(gbt_classifier.stepSize, [0.1, 0.01])\n",
    "             .build())\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(labelCol=\"diabetes\", predictionCol=\"prediction\", metricName=\"accuracy\"),\n",
    "                          numFolds=5)\n",
    "cvModel = crossval.fit(train_data)\n",
    "\n",
    "\n",
    "bestPipeline = cvModel.bestModel\n",
    "bestGBT = bestPipeline.stages[1]\n",
    "print(\"Best Max Depth: \", bestGBT._java_obj.getMaxDepth())\n",
    "print(\"Best Max Iterations: \", bestGBT._java_obj.getMaxIter())\n",
    "print(\"Best Step Size: \", bestGBT._java_obj.getStepSize())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8037a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_gbt = cvModel.transform(test_data)\n",
    "\n",
    "accuracy_gbt = MulticlassClassificationEvaluator(labelCol=\"diabetes\", predictionCol=\"prediction\", metricName=\"accuracy\").evaluate(predictions_gbt)\n",
    "\n",
    "predictionLabels_gbt = predictions_gbt.select(\"prediction\", \"diabetes\").rdd\n",
    "metrics_gbt = MulticlassMetrics(predictionLabels_gbt)\n",
    "\n",
    "precision_0_gbt = metrics_gbt.precision(label=0.0)\n",
    "recall_0_gbt = metrics_gbt.recall(label=0.0)\n",
    "f1Score_0_gbt = metrics_gbt.fMeasure(label=0.0)\n",
    "precision_1_gbt = metrics_gbt.precision(label=1.0)\n",
    "recall_1_gbt = metrics_gbt.recall(label=1.0)\n",
    "f1Score_1_gbt = metrics_gbt.fMeasure(label=1.0)\n",
    "\n",
    "print(f\"Gradient Boosted Trees - Accuracy: {accuracy_gbt:.4f}\")\n",
    "print(f\"Gradient Boosted Trees - 0 - Precision: {precision_0_gbt:.4f}\")\n",
    "print(f\"Gradient Boosted Trees - 0 - Recall: {recall_0_gbt:.4f}\")\n",
    "print(f\"Gradient Boosted Trees - 0 - F1 Score: {f1Score_0_gbt:.4f}\")\n",
    "print(f\"Gradient Boosted Trees - 1 - Precision: {precision_1_gbt:.4f}\")\n",
    "print(f\"Gradient Boosted Trees - 1 - Recall: {recall_1_gbt:.4f}\")\n",
    "print(f\"Gradient Boosted Trees - 1 - F1 Score: {f1Score_1_gbt:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565ba89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
